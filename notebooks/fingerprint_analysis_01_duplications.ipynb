{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b1dbd0c-8d5a-4dc5-8c79-90500b531676",
   "metadata": {},
   "source": [
    "# Fingerprint duplication analysis\n",
    "## Hypothesis\n",
    "- different molecules (=different inchikey14) should ideally have different fingerprints --> so we search for duplicate fingerprints\n",
    "- particularly \"bad\" are identical fingerprints for very different molecules. Since we cannot easily measure this without applying a reference score, we here simply use the mass difference as an indicator. A large mass difference is hence a proxy for high dissimilarity.\n",
    "\n",
    "## Data\n",
    "\n",
    "We here use the **biostructures dataset** containing 730,464 unique compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5dd7549-fcff-4b6c-bf9a-59feea64424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, rdFingerprintGenerator\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "ROOT = Path(os.getcwd()).parents[0]\n",
    "path_data = os.path.join(Path(ROOT), \"data\")\n",
    "\n",
    "# Add source code path\n",
    "sys.path.insert(0, os.path.join(ROOT, \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb68ed9-80ef-460b-acb5-77e145735b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: use other plotting style\n",
    "#plt.style.use('ggplot')\n",
    "#plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be7191c-518c-41b6-a86d-6d61870bb6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025.03.2\n"
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "print(rdkit.__version__)\n",
    "\n",
    "assert int(rdkit.__version__[:4]) >= 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a4227-67ef-479b-ba8f-e84038a69678",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ed1091-bb74-42d5-86fe-8aef868121ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File biostructures.csv was downloaded successfully to C:\\Users\\Julian\\workspace\\molecular_fingerprint_comparisons\\data\\fleming_data.\n"
     ]
    }
   ],
   "source": [
    "from utils import download_dataset\n",
    "\n",
    "download_dataset(\"https://github.com/boecker-lab/myopic-mces-data/raw/refs/heads/main/biostructures.csv\", os.path.join(path_data, \"fleming_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bae73e7-ea40-4f97-a407-12d93619f434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>inchi_key_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1COCCN1C2=NC(=NC(=N2)NC3=CC(=C(C=C3)C=CC4=C(C...</td>\n",
       "      <td>KFDYZSPFVRTLML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCOC1=C(C=CC(=C1)C=NNC(=O)COC2=C(C=CC(=C2)C)C(...</td>\n",
       "      <td>HINREHSUCWWBNO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCOC1=C(C=CC(=C1)C=NNC(=O)COC2=C(C=CC(=C2)C(C)...</td>\n",
       "      <td>XSJXTRKBEZABIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC1=CC=CC=C1N2C(=NN=C2SCC(=O)NC3=CC(=C(C=C3)Cl...</td>\n",
       "      <td>RGEDPHNWBSQUKZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC1=CC=CC=C1N2C(=NN=C2SCC(=O)NC3=C(C=CC=C3Cl)C...</td>\n",
       "      <td>RPFGFTBJBUHWDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles     inchi_key_1\n",
       "0  C1COCCN1C2=NC(=NC(=N2)NC3=CC(=C(C=C3)C=CC4=C(C...  KFDYZSPFVRTLML\n",
       "1  CCOC1=C(C=CC(=C1)C=NNC(=O)COC2=C(C=CC(=C2)C)C(...  HINREHSUCWWBNO\n",
       "2  CCOC1=C(C=CC(=C1)C=NNC(=O)COC2=C(C=CC(=C2)C(C)...  XSJXTRKBEZABIM\n",
       "3  CC1=CC=CC=C1N2C(=NN=C2SCC(=O)NC3=CC(=C(C=C3)Cl...  RGEDPHNWBSQUKZ\n",
       "4  CC1=CC=CC=C1N2C(=NN=C2SCC(=O)NC3=C(C=CC=C3Cl)C...  RPFGFTBJBUHWDA"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"biostructures.csv\"\n",
    "compounds = pd.read_csv(os.path.join(path_data, \"fleming_data\", filename))\n",
    "\n",
    "compounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e934e93-e8b6-4e49-852a-a4eb255a853d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(718097, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compounds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9aec97-3a92-42e0-b833-33bd8575f60c",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4908f029-942a-40b3-8317-639e5d3d3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import funtion/classes from source code\n",
    "from utils import find_duplicates_with_hashing\n",
    "from fingerprint_computation import FingerprintGenerator, compute_fingerprints_from_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d47094e-7208-411b-82ff-0803c88eaa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_get_mol_from_smiles(smi):\n",
    "    try:\n",
    "        return Chem.MolFromSmiles(smi)\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8ddf3fd-fd4b-4ca8-b32c-b1aa5fcd3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mols_from_smiles(smiles):\n",
    "    # Derive Molecules from smiles\n",
    "    mols = Parallel(n_jobs=-1)(\n",
    "        delayed(_safe_get_mol_from_smiles)(smi) for smi in tqdm(smiles, total=len(smiles), desc=\"Generate Molecules\")\n",
    "    )\n",
    "    return [mol for mol in mols if mol is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb203577-44a5-43e8-8190-d8a9c099444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mass(molecule):\n",
    "    # Calculate the molecular mass\n",
    "    return Descriptors.MolWt(molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dda838ec-d473-44c3-8457-2ec2e99a92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from map4 import MAP4\n",
    "from mbp import MBP\n",
    "\n",
    "def compute_map_fingerprints_from_smiles(smiles, map_generator):\n",
    "    molecules = get_mols_from_smiles(list(compounds.smiles))\n",
    "    \n",
    "    fingerprints_map: np.ndarray = map_generator.calculate_many(\n",
    "        molecules,\n",
    "        number_of_threads=mp.cpu_count(),\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    return np.array(list(fingerprints_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fac8479-15f0-45a8-967d-138f0a2d5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: add other fingerprints, e.g. Biosynfoni\n",
    "\n",
    "from biosynfoni import Biosynfoni\n",
    "\n",
    "class BiosynfoniWrapper:       \n",
    "    def GetCountFingerprintAsNumPy(self, mol):\n",
    "        return Biosynfoni(mol).fingerprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be322b71-66d1-497c-b7ef-66585a417cc1",
   "metadata": {},
   "source": [
    "## Compute all compound masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ba712a5-8552-482e-8d5c-119fc9b9f10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e7ed3297544bb3be87ba18a563e7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Molecules:   0%|          | 0/718097 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b015b51a0b204e4faf7bbe5ce5cd84ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculate masses:   0%|          | 0/718067 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Derive Molecules from SMILES\n",
    "mols = get_mols_from_smiles(list(compounds.smiles))\n",
    "#Calculate masses\n",
    "masses = np.array([calculate_mass(mol) for mol in tqdm(mols, desc=\"Calculate masses\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ae950-b059-4b5b-8754-5aa62aec482a",
   "metadata": {},
   "source": [
    "## Run experiments\n",
    "\n",
    "Compute fingerprints and detect duplicates.\n",
    "This takes some time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd317d94-8271-411e-b251-2f88fa43ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    (\"morgan2_count\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096), True),\n",
    "    (\"morgan3_count\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096), True),\n",
    "    (\"morgan6_count\", rdFingerprintGenerator.GetMorganGenerator(radius=6, fpSize=4096), True),\n",
    "    (\"morgan9_count\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=4096), True),\n",
    "    (\"morgan12_count\", rdFingerprintGenerator.GetMorganGenerator(radius=12, fpSize=4096), True),\n",
    "    (\"morgan2_binary\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096), False),\n",
    "    (\"morgan3_binary\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096), False),\n",
    "    (\"morgan6_binary\", rdFingerprintGenerator.GetMorganGenerator(radius=6, fpSize=4096), False),\n",
    "    (\"morgan9_binary\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=4096), False),\n",
    "    (\"morgan12_binary\", rdFingerprintGenerator.GetMorganGenerator(radius=12, fpSize=4096), False),\n",
    "    (\"morgan2_binary_1024\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=1024), False),\n",
    "    (\"morgan3_binary_1024\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=1024), False),\n",
    "    (\"morgan6_binary_1024\", rdFingerprintGenerator.GetMorganGenerator(radius=6, fpSize=1024), False),\n",
    "    (\"morgan9_binary_1024\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=1024), False),\n",
    "    (\"rdkit\", rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=4096), False),\n",
    "    (\"rdkit_1024\", rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=1024), False),\n",
    "    (\"map2\", MAP4(dimensions=4096, radius=1, include_duplicated_shingles=False), False),\n",
    "    (\"map4\", MAP4(dimensions=4096, radius=2, include_duplicated_shingles=False), False),\n",
    "    (\"map4_1024\", MAP4(dimensions=1024, radius=2, include_duplicated_shingles=False), False),\n",
    "    #(\"biosynphoni\", BiosynfoniWrapper(), True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a6cc9-c3c2-4ebd-81eb-9d8c279de6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to store collected duplicates and bit occupations\n",
    "path_results = os.path.join(Path(ROOT), \"experiments\")\n",
    "Path(path_results).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for experiment in experiments:\n",
    "    (name, fpgen, count) = experiment\n",
    "    if os.path.exists(os.path.join(path_results, f\"{name}_duplicates.pickle\")):\n",
    "        print(f\"----- Found existing results for experiment: {name} -----\")\n",
    "        print(f\"----- (experiment will be skipped) -----\")\n",
    "        continue\n",
    "\n",
    "    print(f\"----- Experiment: {name} -----\")\n",
    "\n",
    "    if \"map\" in name:\n",
    "        fingerprints = compute_map_fingerprints_from_smiles(compounds.smiles, fpgen)\n",
    "    else:\n",
    "        fingerprints = compute_fingerprints_from_smiles(\n",
    "            compounds.smiles, fpgen, sparse=False,\n",
    "            count=count, progress_bar=True\n",
    "        )\n",
    "        fingerprints = np.stack(fingerprints)\n",
    "\n",
    "    print(f\"Collected {fingerprints.shape[0]} fingerprints.\")\n",
    "\n",
    "    bins_occupied = (fingerprints > 0).sum(axis=0).astype(np.float64)\n",
    "    bins_occupied *= (100 / len(fingerprints))\n",
    "    np.save(os.path.join(path_results, f\"{name}_bins_occupied.npy\"), bins_occupied)\n",
    "\n",
    "    print(f\"# of bins occupied in 1% or more of all fingerprints: {(bins_occupied >= 1).sum()}\")\n",
    "    print(f\"# of bins occupied in 10% or more of all fingerprints: {(bins_occupied >= 10).sum()}\")\n",
    "    print(f\"# of bins occupied in 50% or more of all fingerprints: {(bins_occupied >= 50).sum()}\")\n",
    "\n",
    "    # Search fingerprint duplicated\n",
    "    duplicates = find_duplicates_with_hashing(fingerprints)\n",
    "    duplicate_statistics = np.array([len(x) for x in duplicates])\n",
    "    with open(os.path.join(path_results, f\"{name}_duplicates.pickle\"), \"wb\") as handle:\n",
    "        pickle.dump(duplicates, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"Total of {sum(duplicate_statistics)} compounds have duplicated fingerprints.\")\n",
    "    print(f\"The largest cluster has {max(duplicate_statistics)} compounds with identical fingerprint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c559b-5a30-4298-acf7-40ecb74ec0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to store collected duplicates and bit occupations\n",
    "path_results = os.path.join(Path(ROOT), \"experiments\", \"fingerprint_duplicates\")\n",
    "Path(path_results).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for experiment in experiments:\n",
    "    (name, fpgen, count) = experiment\n",
    "    if os.path.exists(os.path.join(path_results, f\"{name}_duplicates.pickle\")):\n",
    "        print(f\"----- Found existing results for experiment: {name} -----\")\n",
    "        print(f\"----- (experiment will be skipped) -----\")\n",
    "        continue\n",
    "\n",
    "    print(f\"----- Experiment: {name} -----\")\n",
    "\n",
    "    if \"map\" in name:\n",
    "        fingerprints = compute_map_fingerprints_from_smiles(compounds.smiles, fpgen)\n",
    "    else:\n",
    "        fingerprints = compute_fingerprints_from_smiles(\n",
    "            compounds.smiles, fpgen, sparse=False,\n",
    "            count=count, progress_bar=True\n",
    "        )\n",
    "        fingerprints = np.stack(fingerprints)\n",
    "\n",
    "    print(f\"Collected {fingerprints.shape[0]} fingerprints.\")\n",
    "\n",
    "    bins_occupied = (fingerprints > 0).sum(axis=0).astype(np.float64)\n",
    "    bins_occupied *= (100 / len(fingerprints))\n",
    "    np.save(os.path.join(path_results, f\"{name}_bins_occupied.npy\"), bins_occupied)\n",
    "\n",
    "    print(f\"# of bins occupied in 1% or more of all fingerprints: {(bins_occupied >= 1).sum()}\")\n",
    "    print(f\"# of bins occupied in 10% or more of all fingerprints: {(bins_occupied >= 10).sum()}\")\n",
    "    print(f\"# of bins occupied in 50% or more of all fingerprints: {(bins_occupied >= 50).sum()}\")\n",
    "\n",
    "    # Search fingerprint duplicated\n",
    "    duplicates = find_duplicates_with_hashing(fingerprints)\n",
    "    duplicate_statistics = np.array([len(x) for x in duplicates])\n",
    "    with open(os.path.join(path_results, f\"{name}_duplicates.pickle\"), \"wb\") as handle:\n",
    "        pickle.dump(duplicates, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"Total of {sum(duplicate_statistics)} compounds have duplicated fingerprints.\")\n",
    "    print(f\"The largest cluster has {max(duplicate_statistics)} compounds with identical fingerprint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea76866-d150-4aa0-a7ac-331076029e28",
   "metadata": {},
   "source": [
    "## Run experiments II - sparse\n",
    "\n",
    "Compute fingerprints and detect duplicates.\n",
    "This takes some time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061dd74-e931-4e7b-afd3-d61476a47c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from rdkit.Chem import Mol\n",
    "\n",
    "def compute_map_fingerprints_from_smiles(smiles, map_generator):\n",
    "    \n",
    "    molecules: List[Mol] = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "    fingerprints_map: np.ndarray = map_generator.calculate_many(\n",
    "        molecules,\n",
    "        number_of_threads=32,\n",
    "        verbose=True,\n",
    "    )\n",
    "    return list(fingerprints_map)\n",
    "\n",
    "\n",
    "def compute_sparse_map_fingerprints_from_smiles(\n",
    "    smiles,\n",
    "    map_generator,\n",
    "    count=False,\n",
    "    ):\n",
    "    molecules: List[Mol] = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "    fingerprints_map: np.ndarray = map_generator.calculate_many_sparse(\n",
    "        molecules,\n",
    "        number_of_threads=32,\n",
    "        verbose=True,\n",
    "        count=count,\n",
    "    )\n",
    "    return list(fingerprints_map)\n",
    "\n",
    "\n",
    "def compute_sparse_map_fingerprints_from_smiles_serial(\n",
    "        smiles,\n",
    "        map_generator\n",
    "        ):\n",
    "\n",
    "    molecules: List[Mol] = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "    fingerprints = []\n",
    "    for mol in tqdm(molecules):\n",
    "        fp_bits = map_generator._calculate(mol)\n",
    "        fingerprints.append(np.sort(map_generator.encoder.hash(fp_bits)))\n",
    "    return fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df62bb0-43a2-4ff7-9e8d-935017abf401",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    (\"morgan2_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096), True),\n",
    "    (\"morgan3_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096), True),\n",
    "    #(\"morgan6_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=6, fpSize=4096), True),\n",
    "    (\"morgan9_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=4096), True),\n",
    "    (\"morgan12_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=12, fpSize=4096), True),\n",
    "    (\"morgan2_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096), False),\n",
    "    (\"morgan3_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096), False),\n",
    "    (\"morgan9_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=4096), False),\n",
    "    (\"morgan12_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=12, fpSize=4096), False),\n",
    "    (\"rdkit_sparse\", rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=4096), False),\n",
    "    (\"map2_sparse\", MAP4(dimensions=4096, radius=1, include_duplicated_shingles=False), False),\n",
    "    (\"map4_sparse\", MAP4(dimensions=4096, radius=2, include_duplicated_shingles=False), False),\n",
    "    (\"mbp2_sparse\", MBP(dimensions=4096, radius=1), False),\n",
    "    (\"mbp2_binned_sparse\", MBP(dimensions=4096, radius=1, dist_binning=np.array([0, 1, 2, 4, 8, 16, 32, 64])), False),\n",
    "    (\"mbp2_count_sparse\", MBP(dimensions=4096, radius=1), True),\n",
    "    (\"mbp2_binned_count_sparse\", MBP(dimensions=4096, radius=1, dist_binning=np.array([0, 1, 2, 4, 8, 16, 32, 64])), True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a743dde-ddfa-488b-9ef7-ddc53a126145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to store collected duplicates and bit occupations\n",
    "path_results = os.path.join(Path(ROOT), \"experiments\")\n",
    "\n",
    "for experiment in experiments:\n",
    "    (name, fpgen, count) = experiment\n",
    "    if os.path.exists(os.path.join(path_results, f\"{name}_duplicates.pickle\")):\n",
    "        print(f\"----- Found existing results for experiment: {name} -----\")\n",
    "        print(f\"----- (experiment will be skipped) -----\")\n",
    "        continue\n",
    "\n",
    "    print(f\"----- Experiment: {name} -----\")\n",
    "\n",
    "    if (\"map\" in name):\n",
    "        fingerprints = compute_sparse_map_fingerprints_from_smiles_serial(compounds.smiles, fpgen)\n",
    "    elif (\"mbp\" in name):\n",
    "        if count:\n",
    "            fingerprints = compute_sparse_map_fingerprints_from_smiles(compounds.smiles, fpgen, count=True)\n",
    "            fingerprints = [(x[0], x[1]) for x in fingerprints]\n",
    "        else:\n",
    "            fingerprints = compute_sparse_map_fingerprints_from_smiles(compounds.smiles, fpgen)\n",
    "    else:\n",
    "        fingerprints = compute_fingerprints_from_smiles(\n",
    "            compounds.smiles, fpgen, sparse=True,\n",
    "            count=count, progress_bar=True\n",
    "        )\n",
    "\n",
    "    print(f\"Collected {len(fingerprints)} fingerprints.\")\n",
    "\n",
    "    # Bit statistics\n",
    "    if isinstance(fingerprints[0], tuple):\n",
    "        number_of_bits = np.array([len(x[0]) for x in fingerprints])\n",
    "    else:\n",
    "        number_of_bits = np.array([len(x) for x in fingerprints])\n",
    "    np.save(os.path.join(path_results, f\"{name}_number_of_bits.npy\"), number_of_bits)\n",
    "\n",
    "    # Search fingerprint duplicated\n",
    "    duplicates = find_duplicates_with_hashing(fingerprints)\n",
    "    duplicate_statistics = np.array([len(x) for x in duplicates])\n",
    "    with open(os.path.join(path_results, f\"{name}_duplicates.pickle\"), \"wb\") as handle:\n",
    "        pickle.dump(duplicates, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"Total of {sum(duplicate_statistics)} compounds have duplicated fingerprints.\")\n",
    "    if len(duplicate_statistics) > 0:\n",
    "        print(f\"The largest cluster has {max(duplicate_statistics)} compounds with identical fingerprint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4762ef05-c368-43c6-8304-2641da81ee6b",
   "metadata": {},
   "source": [
    "## Compare experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e15ec-0919-4004-9da0-4362669773d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    (\"morgan2_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096), True),\n",
    "    (\"morgan3_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096), True),\n",
    "    #(\"morgan6_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=6, fpSize=4096), True),\n",
    "    (\"morgan9_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=4096), True),\n",
    "    (\"morgan12_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=12, fpSize=4096), True),\n",
    "    (\"morgan2_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096), False),\n",
    "    (\"morgan3_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096), False),\n",
    "    (\"morgan9_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=4096), False),\n",
    "    (\"morgan12_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=12, fpSize=4096), False),\n",
    "    (\"rdkit_sparse\", rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=4096), False),\n",
    "    (\"map2_sparse\", MAP4(dimensions=4096, radius=1, include_duplicated_shingles=False), False),\n",
    "    (\"map4_sparse\", MAP4(dimensions=4096, radius=2, include_duplicated_shingles=False), False),\n",
    "    #(\"mbp2_sparse\", MBP(dimensions=4096, radius=1), False),\n",
    "    #(\"mbp2_binned_sparse\", MBP(dimensions=4096, radius=1, dist_binning=np.array([0, 1, 2, 4, 8, 16, 32, 64])), False),\n",
    "    #(\"mbp2_count_sparse\", MBP(dimensions=4096, radius=1), True),\n",
    "    #(\"mbp2_binned_count_sparse\", MBP(dimensions=4096, radius=1, dist_binning=np.array([0, 1, 2, 4, 8, 16, 32, 64])), True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2fa7e7-0424-4f03-b9e6-a2289da19cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group_mass_diff(group_indices, masses):\n",
    "    \"\"\"\n",
    "    Given a list/array of indices corresponding to compounds in a duplicate group,\n",
    "    compute the mass range (max - min) for that group.\n",
    "    \"\"\"\n",
    "    group_masses = masses[group_indices]\n",
    "    return group_masses.max() - group_masses.min()\n",
    "\n",
    "\n",
    "results_folder = os.path.join(Path(ROOT), \"experiments\", \"fingerprint_duplicates\")\n",
    "experiment_names = [x[0] for x in experiments]\n",
    "experiment_names.extend([x[0].replace(\"_sparse\", \"\") for x in experiments])\n",
    "\n",
    "\n",
    "results = []\n",
    "for exp_name in tqdm(experiment_names):\n",
    "    dup_file = os.path.join(results_folder, f\"{exp_name}_duplicates.pickle\")\n",
    "    bins_file = os.path.join(results_folder, f\"{exp_name}_bins_occupied.npy\")\n",
    "    bit_number_file = os.path.join(results_folder, f\"{exp_name}_number_of_bits.npy\")\n",
    "    \n",
    "    # If either file is missing, skip this experiment.\n",
    "    if not os.path.exists(dup_file) and (os.path.exists(bins_file) or os.path.exists(bit_number_file)):\n",
    "        print(f\"Results for experiment {exp_name} not found, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load duplicate groups.\n",
    "    with open(dup_file, \"rb\") as f:\n",
    "        duplicates = pickle.load(f)\n",
    "\n",
    "    # Total duplicates: count all compounds that appear in any duplicate group.\n",
    "    total_duplicates = sum(len(group) for group in duplicates)\n",
    "    \n",
    "    # Count the duplicates in groups where the max-mass difference is at least 200.\n",
    "    duplicates_mass_diff = 0\n",
    "    for group in duplicates:\n",
    "        # Convert group to a NumPy array (if not already) to index into masses.\n",
    "        group_indices = np.array(group)\n",
    "        if len(group_indices) == 0:\n",
    "            continue  # Skip if group is empty for any reason.\n",
    "        mass_diff = compute_group_mass_diff(group_indices, masses)\n",
    "        if mass_diff >= 200:\n",
    "            duplicates_mass_diff += len(group_indices)\n",
    "\n",
    "    if \"_sparse\" in exp_name:\n",
    "        # Load the bit data.\n",
    "        bit_numbers = np.load(bit_number_file)\n",
    "        mean_bins = bit_numbers.mean()\n",
    "    else:\n",
    "        # Load the bins occupancy data.\n",
    "        bins_occupied = np.load(bins_file)\n",
    "        mean_bins = bins_occupied.mean() / 100 * len(bins_occupied)\n",
    "\n",
    "    # Append the experiment summary to our results list.\n",
    "    results.append({\n",
    "        \"experiment\": exp_name,\n",
    "        \"total_duplicates\": total_duplicates,\n",
    "        \"duplicates_mass_diff_ge_200\": duplicates_mass_diff,\n",
    "        \"mean_bins_occupied\": mean_bins,\n",
    "    })\n",
    "\n",
    "# Create a Pandas DataFrame for a neat summary.\n",
    "df_results = pd.DataFrame(results).sort_values(\"experiment\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b5b45-63f1-4f09-858f-f738f4060bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "df_results.to_csv(\"results_table_fingerprint_statistics_250505.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e0f24c-60df-4a61-8546-1c9099d9aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_experiments = [\n",
    "    (\"rdkit\", \"RDKit fingerprint (4096 bits)\"),\n",
    "    (\"rdkit_1024\", \"RDKit fingerprint (1024 bits)\"),\n",
    "    (\"morgan2_binary\", \"Morgan-2 fingerprint (4096 bits)\"),\n",
    "    (\"morgan2_count\", \"Morgan-2 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan2_binary_1024\", \"Morgan-2 fingerprint (1024 bits)\"),\n",
    "    (\"morgan3_binary\", \"Morgan-3 fingerprint (4096 bits)\"),\n",
    "    (\"morgan3_count\", \"Morgan-3 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan3_binary_1024\", \"Morgan-3 fingerprint (1024 bits)\"),\n",
    "    #(\"morgan6_count\", \"Morgan-6 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan6_binary\", \"Morgan-6 fingerprint (4096 bits)\"),\n",
    "    (\"morgan6_binary_1024\", \"Morgan-6 fingerprint (1024 bits)\"),\n",
    "    (\"morgan9_binary\", \"Morgan-9 fingerprint (4096 bits)\"),\n",
    "    (\"morgan9_binary_1024\", \"Morgan-9 fingerprint (1024 bits)\"),\n",
    "    (\"map4\", \"MAP4 fingerprint (4096 bits)\"),\n",
    "    (\"map4_1024\", \"MAP4 fingerprint (1024 bits)\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d63dc9b-8d09-47f4-87f3-3d0446a9a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    \"#00A878\", \"#00A878\",\n",
    "    \"#fad02c\", \"#fad02c\",\n",
    "    \"#f98517\", \"#f98517\",\n",
    "    #\"#c85b00\", \"#c85b00\",\n",
    "    \"#ac0000\", \"#ac0000\",\n",
    "    \"#680000\", \"#680000\",\n",
    "    \"#3333D1\", \"#3333D1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f23ec3-9be1-4831-92e1-1191c437c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5), dpi=300)\n",
    "\n",
    "fig_i = -1\n",
    "for i, (file, name) in enumerate(files_experiments):\n",
    "    if \"count\" in name:\n",
    "        if file[:7]+\"_binary\" in [x[0] for x in files_experiments]:\n",
    "            continue\n",
    "    fig_i += 1\n",
    "    bins_occupied = np.load(os.path.join(path_results, f\"{file}_bins_occupied.npy\"))\n",
    "    order = np.argsort(bins_occupied)[::-1]\n",
    "    bins_scaled = np.linspace(0, 100, len(bins_occupied))\n",
    "\n",
    "\n",
    "    if \"1024\" in name:\n",
    "        ax.plot(bins_scaled, bins_occupied[order], \":\", linewidth=1.5, color=colors[fig_i], alpha=0.9, label=name.replace(\" count\", \"\"))\n",
    "    else:\n",
    "        ax.plot(bins_scaled, bins_occupied[order], linewidth=1.5, color=colors[fig_i], label=name.replace(\" count\", \"\"))\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"bit occupation [%]\")\n",
    "ax.set_xlabel(\"vector length [%]\")\n",
    "ax.set_xlim([0, 100])\n",
    "ax.set_ylim([0, 100])\n",
    "\n",
    "# Grid\n",
    "ax.grid(which='major', color='#DDDDDD', linewidth=1)\n",
    "ax.grid(which='minor', color='#EEEEEE', linestyle=':', linewidth=0.75)\n",
    "\n",
    "plt.legend(fontsize=7)\n",
    "plt.savefig(\"Bit_occupation_distributions_scaled_730k.pdf\")\n",
    "plt.savefig(\"Bit_occupation_distributions_scaled_730k.png\", dpi=450)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc2eff-6ee4-4ceb-8f9f-31510ef5f8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e002e-af82-472f-a487-93cf6633b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "#plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cbe812-5d2c-49df-800f-17c6d6aed187",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_experiments = [\n",
    "    (\"rdkit\", \"RDKit fingerprint (4096 bits)\"),\n",
    "    (\"rdkit_1024\", \"RDKit fingerprint (1024 bits)\"),\n",
    "    (\"morgan2_binary\", \"Morgan-2 fingerprint (4096 bits)\"),\n",
    "    (\"morgan2_count\", \"Morgan-2 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan2_binary_1024\", \"Morgan-2 fingerprint (1024 bits)\"),\n",
    "    (\"morgan3_binary\", \"Morgan-3 fingerprint (4096 bits)\"),\n",
    "    (\"morgan3_count\", \"Morgan-3 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan3_binary_1024\", \"Morgan-3 fingerprint (1024 bits)\"),\n",
    "    (\"morgan4_count\", \"Morgan-4 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan5_count\", \"Morgan-5 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan6_count\", \"Morgan-6 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan6_binary_1024\", \"Morgan-6 fingerprint (1024 bits)\"),\n",
    "    (\"map4_4096\", \"MAP4 fingerprint (r=2, 4096 bits)\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051f7607-5248-4cb1-ad03-16e8eaf7ccfb",
   "metadata": {},
   "source": [
    "## TAKE CARE: this will take the max difference per duplicates group\n",
    "This is rather pessimistic, but might give an idea of the \"risk\" to find *very* different compounds for the same fingerprints.\n",
    "\n",
    "After all 5 identical fingerprints with masses [200, 210, 350, 380, 500] would not all correspond to a max mass difference of 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90451ece-930b-4b7a-ad1f-98e33589c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_compound_max_differences(masses):\n",
    "    all_max_diffs = []\n",
    "    min_mass = masses.min()\n",
    "    max_mass = masses.max()\n",
    "    for mass in masses:\n",
    "        max_diff = max(mass - min_mass, max_mass - mass)\n",
    "        all_max_diffs.append(max_diff)\n",
    "\n",
    "    return np.array(all_max_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5396df-3dab-4565-9845-9ee1929c9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#00A878\", \"#6CCD8C\",\n",
    "          \"#E6D98C\", \"#F1C178\",\n",
    "          \"#F16666\", \"#DD2222\",\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc0fec0-1587-4e4d-b2a2-14f706f2c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_experiments = [\n",
    "    (\"rdkit\", \"RDKit fingerprint (4096 bits)\"),\n",
    "    (\"rdkit_1024\", \"RDKit fingerprint (1024 bits)\"),\n",
    "    (\"morgan2_binary\", \"Morgan-2 fingerprint (4096 bits)\"),\n",
    "    (\"morgan2_count\", \"Morgan-2 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan2_binary_1024\", \"Morgan-2 fingerprint (1024 bits)\"),\n",
    "    (\"morgan3_binary\", \"Morgan-3 fingerprint (4096 bits)\"),\n",
    "    (\"morgan3_count\", \"Morgan-3 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan3_binary_1024\", \"Morgan-3 fingerprint (1024 bits)\"),\n",
    "    (\"morgan6_count\", \"Morgan-6 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan6_binary\", \"Morgan-6 fingerprint (4096 bits)\"),\n",
    "    (\"morgan6_binary_1024\", \"Morgan-6 fingerprint (1024 bits)\"),\n",
    "    (\"morgan9_count\", \"Morgan-9 count fingerprint (4096 bits)\"),\n",
    "    #(\"map2\", \"MAP2 fingerprint (4096 bits)\"),\n",
    "    (\"map4\", \"MAP4 fingerprint (4096 bits)\"),\n",
    "    (\"map4_1024\", \"MAP4 fingerprint (1024 bits)\"),\n",
    "    #(\"biosynphoni\", \"Biosynfoni fingerprint\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa798e-ce31-4487-b2b4-dca56592fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bins\n",
    "bins = [(0, 1), (1, 50), (50, 100), (100, 200), (200, 400), (400, np.inf)]\n",
    "bin_labels = [f\"{low}-{high} Da\" if high != np.inf else f\"{low}-inf Da\" for low, high in bins]\n",
    "\n",
    "\n",
    "# Initialize results storage\n",
    "experiment_sums = {name: np.zeros(len(bins)) for _, name in files_experiments}\n",
    "\n",
    "# Process each experiment\n",
    "for file, name in files_experiments:\n",
    "    # Load duplicates data\n",
    "    with open(os.path.join(path_results, f\"{file}_duplicates.pickle\"), \"rb\") as f:\n",
    "        duplicates = pickle.load(f)\n",
    "\n",
    "    # Calculate statistics\n",
    "    duplicate_statistics = np.array([len(x) for x in duplicates])\n",
    "    duplicate_masses = [masses[i] for i in duplicates]\n",
    "    max_mass_differences = np.concatenate([compute_compound_max_differences(x) for x in duplicate_masses])\n",
    "\n",
    "    # Compute sums for each bin\n",
    "    for i, (low, high) in enumerate(bins):\n",
    "        idx = np.where((max_mass_differences >= low) & (max_mass_differences < high))[0]\n",
    "        experiment_sums[name][i] = idx.shape[0]\n",
    "\n",
    "# Sort experiments by total sum\n",
    "sorted_experiments = sorted(\n",
    "    experiment_sums.items(), \n",
    "    key=lambda item: item[1].sum(), \n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Prepare for stacked bar chart\n",
    "width = 0.5\n",
    "y_positions = np.arange(len(sorted_experiments))\n",
    "left_stack = np.zeros(len(sorted_experiments))\n",
    "\n",
    "# Iterate over bins and stack their sums\n",
    "for i, label in enumerate(bin_labels):\n",
    "    values = [experiment[1][i] for experiment in sorted_experiments]\n",
    "    ax.barh(y_positions, values, width, label=label, left=left_stack, color=colors[i])\n",
    "    left_stack += values\n",
    "\n",
    "# Add numbers\n",
    "for i, y in enumerate(y_positions):\n",
    "    value = sorted_experiments[i][1].sum()\n",
    "    plt.text(value, i-0.1, f\"{value:.0f}\", fontsize=9)\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(which='major', color='#DDDDDD', linewidth=1)\n",
    "\n",
    "# Configure plot appearance\n",
    "ax.set_yticks(y_positions)\n",
    "ax.set_yticklabels([experiment[0] for experiment in sorted_experiments])\n",
    "ax.set_xlabel(\"Compounds with Fingerprint Duplicates\")\n",
    "ax.set_title(\"Duplicate Statistics by Experiment (Sorted by total duplicates)\")\n",
    "ax.legend(title=\"Maximum mass difference\\n(for identical fingerprints)\", loc=\"upper right\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Duplicate_statistics_max_mass_difference_730k.pdf\")\n",
    "plt.savefig(\"Duplicate_statistics_max_mass_difference_730k.png\", dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a27dab-c2da-424d-a9d2-76ac9bb5ff6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
