{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b1dbd0c-8d5a-4dc5-8c79-90500b531676",
   "metadata": {},
   "source": [
    "# Fingerprint duplication analysis\n",
    "## Hypothesis\n",
    "- different molecules (=different inchikey14) should ideally have different fingerprints --> so we search for duplicate fingerprints\n",
    "- particularly \"bad\" are identical fingerprints for very different molecules. Since we cannot easily measure this without applying a reference score, we here simply use the mass difference as an indicator. A large mass difference is hence a proxy for high dissimilarity.\n",
    "\n",
    "## Data\n",
    "\n",
    "We here use the **biostructures dataset** containing 730,464 unique compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5dd7549-fcff-4b6c-bf9a-59feea64424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, rdFingerprintGenerator\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "ROOT = Path(os.getcwd()).parents[0]\n",
    "path_data = os.path.join(Path(ROOT), \"data\")\n",
    "\n",
    "# Add source code path\n",
    "sys.path.insert(0, os.path.join(ROOT, \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb68ed9-80ef-460b-acb5-77e145735b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: use other plotting style\n",
    "#plt.style.use('ggplot')\n",
    "#plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be7191c-518c-41b6-a86d-6d61870bb6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025.03.2\n"
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "print(rdkit.__version__)\n",
    "\n",
    "assert int(rdkit.__version__[:4]) >= 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a4227-67ef-479b-ba8f-e84038a69678",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bae73e7-ea40-4f97-a407-12d93619f434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>inchi_key_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1COCCN1C2=NC(=NC(=N2)NC3=CC(=C(C=C3)C=CC4=C(C...</td>\n",
       "      <td>KFDYZSPFVRTLML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCOC1=C(C=CC(=C1)C=NNC(=O)COC2=C(C=CC(=C2)C)C(...</td>\n",
       "      <td>HINREHSUCWWBNO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCOC1=C(C=CC(=C1)C=NNC(=O)COC2=C(C=CC(=C2)C(C)...</td>\n",
       "      <td>XSJXTRKBEZABIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC1=CC=CC=C1N2C(=NN=C2SCC(=O)NC3=CC(=C(C=C3)Cl...</td>\n",
       "      <td>RGEDPHNWBSQUKZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC1=CC=CC=C1N2C(=NN=C2SCC(=O)NC3=C(C=CC=C3Cl)C...</td>\n",
       "      <td>RPFGFTBJBUHWDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles     inchi_key_1\n",
       "0  C1COCCN1C2=NC(=NC(=N2)NC3=CC(=C(C=C3)C=CC4=C(C...  KFDYZSPFVRTLML\n",
       "1  CCOC1=C(C=CC(=C1)C=NNC(=O)COC2=C(C=CC(=C2)C)C(...  HINREHSUCWWBNO\n",
       "2  CCOC1=C(C=CC(=C1)C=NNC(=O)COC2=C(C=CC(=C2)C(C)...  XSJXTRKBEZABIM\n",
       "3  CC1=CC=CC=C1N2C(=NN=C2SCC(=O)NC3=CC(=C(C=C3)Cl...  RGEDPHNWBSQUKZ\n",
       "4  CC1=CC=CC=C1N2C(=NN=C2SCC(=O)NC3=C(C=CC=C3Cl)C...  RPFGFTBJBUHWDA"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"biostructures.csv\"\n",
    "compounds = pd.read_csv(os.path.join(path_data, \"fleming_data\", filename))\n",
    "\n",
    "compounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e934e93-e8b6-4e49-852a-a4eb255a853d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(718097, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compounds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9aec97-3a92-42e0-b833-33bd8575f60c",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4908f029-942a-40b3-8317-639e5d3d3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import funtion/classes from source code\n",
    "from utils import find_duplicates_with_hashing\n",
    "from fingerprint_computation import FingerprintGenerator, compute_fingerprints_from_smiles, get_mol_from_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb203577-44a5-43e8-8190-d8a9c099444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mass(smiles):\n",
    "    # Convert SMILES string to a molecule object\n",
    "    molecule = get_mol_from_smiles(smiles)\n",
    "    if molecule is None:\n",
    "        return \"Invalid SMILES\"\n",
    "    # Calculate the molecular mass\n",
    "    return Descriptors.MolWt(molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dda838ec-d473-44c3-8457-2ec2e99a92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from map4 import MAP4\n",
    "from mbp import MBP\n",
    "\n",
    "def compute_map_fingerprints_from_smiles(smiles, map_generator):\n",
    "    molecules = [mol for s in tqdm(smiles, total=len(smiles), desc=\"Generate Molecules\") if (mol := get_mol_from_smiles(s)) is not None]\n",
    "    fingerprints_map: np.ndarray = map_generator.calculate_many(\n",
    "        molecules,\n",
    "        number_of_threads=multiprocessing.cpu_count(),\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    return np.array(list(fingerprints_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fac8479-15f0-45a8-967d-138f0a2d5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: add other fingerprints, e.g. Biosynfoni\n",
    "\n",
    "from biosynfoni import Biosynfoni\n",
    "\n",
    "class BiosynfoniWrapper:       \n",
    "    def GetCountFingerprintAsNumPy(self, mol):\n",
    "        return Biosynfoni(mol).fingerprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be322b71-66d1-497c-b7ef-66585a417cc1",
   "metadata": {},
   "source": [
    "## Compute all compound masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "997401ec-4e64-439b-8193-78521c9f3f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926a1806c87248bebe6fc0cc514ea0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/718097 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smiles_strings = list(compounds.smiles)\n",
    "masses = Parallel(n_jobs=-1)(\n",
    "    delayed(calculate_mass)(smi) for smi in tqdm(smiles_strings)\n",
    ")\n",
    "\n",
    "masses = np.array(masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ae950-b059-4b5b-8754-5aa62aec482a",
   "metadata": {},
   "source": [
    "## Run experiments\n",
    "\n",
    "Compute fingerprints and detect duplicates.\n",
    "This takes some time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd317d94-8271-411e-b251-2f88fa43ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    (\"morgan2_count\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096), True),\n",
    "    (\"morgan3_count\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096), True),\n",
    "    (\"morgan6_count\", rdFingerprintGenerator.GetMorganGenerator(radius=6, fpSize=4096), True),\n",
    "    (\"morgan9_count\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=4096), True),\n",
    "    (\"morgan12_count\", rdFingerprintGenerator.GetMorganGenerator(radius=12, fpSize=4096), True),\n",
    "    (\"morgan2_binary\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096), False),\n",
    "    (\"morgan3_binary\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096), False),\n",
    "    (\"morgan6_binary\", rdFingerprintGenerator.GetMorganGenerator(radius=6, fpSize=4096), False),\n",
    "    (\"morgan9_binary\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=4096), False),\n",
    "    (\"morgan12_binary\", rdFingerprintGenerator.GetMorganGenerator(radius=12, fpSize=4096), False),\n",
    "    (\"morgan2_binary_1024\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=1024), False),\n",
    "    (\"morgan3_binary_1024\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=1024), False),\n",
    "    (\"morgan6_binary_1024\", rdFingerprintGenerator.GetMorganGenerator(radius=6, fpSize=1024), False),\n",
    "    (\"morgan9_binary_1024\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=1024), False),\n",
    "    (\"rdkit\", rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=4096), False),\n",
    "    (\"rdkit_1024\", rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=1024), False),\n",
    "    (\"map2\", MAP4(dimensions=4096, radius=1, include_duplicated_shingles=False), False),\n",
    "    (\"map4\", MAP4(dimensions=4096, radius=2, include_duplicated_shingles=False), False),\n",
    "    (\"map4_1024\", MAP4(dimensions=1024, radius=2, include_duplicated_shingles=False), False),\n",
    "    #(\"biosynphoni\", BiosynfoniWrapper(), True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a6cc9-c3c2-4ebd-81eb-9d8c279de6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to store collected duplicates and bit occupations\n",
    "path_results = os.path.join(Path(ROOT), \"experiments\")\n",
    "Path(path_results).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for experiment in experiments:\n",
    "    (name, fpgen, count) = experiment\n",
    "    if os.path.exists(os.path.join(path_results, f\"{name}_duplicates.pickle\")):\n",
    "        print(f\"----- Found existing results for experiment: {name} -----\")\n",
    "        print(f\"----- (experiment will be skipped) -----\")\n",
    "        continue\n",
    "\n",
    "    print(f\"----- Experiment: {name} -----\")\n",
    "\n",
    "    if \"map\" in name:\n",
    "        fingerprints = compute_map_fingerprints_from_smiles(compounds.smiles, fpgen)\n",
    "    else:\n",
    "        fingerprints = compute_fingerprints_from_smiles(\n",
    "            compounds.smiles, fpgen, sparse=False,\n",
    "            count=count, progress_bar=True\n",
    "        )\n",
    "        fingerprints = np.stack(fingerprints)\n",
    "\n",
    "    print(f\"Collected {fingerprints.shape[0]} fingerprints.\")\n",
    "\n",
    "    bins_occupied = (fingerprints > 0).sum(axis=0).astype(np.float64)\n",
    "    bins_occupied *= (100 / len(fingerprints))\n",
    "    np.save(os.path.join(path_results, f\"{name}_bins_occupied.npy\"), bins_occupied)\n",
    "\n",
    "    print(f\"# of bins occupied in 1% or more of all fingerprints: {(bins_occupied >= 1).sum()}\")\n",
    "    print(f\"# of bins occupied in 10% or more of all fingerprints: {(bins_occupied >= 10).sum()}\")\n",
    "    print(f\"# of bins occupied in 50% or more of all fingerprints: {(bins_occupied >= 50).sum()}\")\n",
    "\n",
    "    # Search fingerprint duplicated\n",
    "    duplicates = find_duplicates_with_hashing(fingerprints)\n",
    "    duplicate_statistics = np.array([len(x) for x in duplicates])\n",
    "    with open(os.path.join(path_results, f\"{name}_duplicates.pickle\"), \"wb\") as handle:\n",
    "        pickle.dump(duplicates, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"Total of {sum(duplicate_statistics)} compounds have duplicated fingerprints.\")\n",
    "    print(f\"The largest cluster has {max(duplicate_statistics)} compounds with identical fingerprint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c559b-5a30-4298-acf7-40ecb74ec0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to store collected duplicates and bit occupations\n",
    "path_results = os.path.join(Path(ROOT), \"experiments\", \"fingerprint_duplicates\")\n",
    "Path(path_results).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Run experiments!\n",
    "for experiment in experiments:\n",
    "    (name, fpgen, count) = experiment\n",
    "    if os.path.exists(os.path.join(path_results, f\"{name}_duplicates.pickle\")):\n",
    "        print(f\"----- Found existing results for experiment: {name} -----\")\n",
    "        print(f\"----- (experiment will be skipped) -----\")\n",
    "        continue\n",
    "\n",
    "    print(f\"----- Experiment: {name} -----\")\n",
    "\n",
    "    # Compute fingerprints\n",
    "    if \"map\" in name:\n",
    "        fingerprints = compute_map_fingerprints_from_smiles(compounds.smiles, fpgen)\n",
    "    else:\n",
    "        fingerprints = compute_fingerprints_from_smiles(\n",
    "            compounds.smiles, fpgen, sparse=False,\n",
    "            count=count, progress_bar=True\n",
    "        )\n",
    "        fingerprints = np.stack(fingerprints)\n",
    "\n",
    "    print(f\"Collected {fingerprints.shape[0]} fingerprints.\")\n",
    "\n",
    "    bins_occupied = (fingerprints > 0).sum(axis=0).astype(np.float64)\n",
    "    bins_occupied *= (100 / len(fingerprints))\n",
    "    np.save(os.path.join(path_results, f\"{name}_bins_occupied.npy\"), bins_occupied)\n",
    "\n",
    "    print(f\"# of bins occupied in 1% or more of all fingerprints: {(bins_occupied >= 1).sum()}\")\n",
    "    print(f\"# of bins occupied in 10% or more of all fingerprints: {(bins_occupied >= 10).sum()}\")\n",
    "    print(f\"# of bins occupied in 50% or more of all fingerprints: {(bins_occupied >= 50).sum()}\")\n",
    "\n",
    "    # Search fingerprint duplicates\n",
    "    duplicates = find_duplicates_with_hashing(fingerprints)\n",
    "    duplicate_statistics = np.array([len(x) for x in duplicates])\n",
    "    with open(os.path.join(path_results, f\"{name}_duplicates.pickle\"), \"wb\") as handle:\n",
    "        pickle.dump(duplicates, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"Total of {sum(duplicate_statistics)} compounds have duplicated fingerprints.\")\n",
    "    print(f\"The largest cluster has {max(duplicate_statistics)} compounds with identical fingerprint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea76866-d150-4aa0-a7ac-331076029e28",
   "metadata": {},
   "source": [
    "---\n",
    "# Run experiments II - sparse\n",
    "\n",
    "Compute **sparse fingerprints** and detect duplicates.\n",
    "This takes some time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061dd74-e931-4e7b-afd3-d61476a47c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from rdkit.Chem import Mol\n",
    "\n",
    "def compute_map_fingerprints_from_smiles(smiles, map_generator):\n",
    "    \n",
    "    molecules: List[Mol] = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "    fingerprints_map: np.ndarray = map_generator.calculate_many(\n",
    "        molecules,\n",
    "        number_of_threads=32,\n",
    "        verbose=True,\n",
    "    )\n",
    "    return list(fingerprints_map)\n",
    "\n",
    "\n",
    "def compute_sparse_map_fingerprints_from_smiles(\n",
    "    smiles,\n",
    "    map_generator,\n",
    "    count=False,\n",
    "    ):\n",
    "    molecules: List[Mol] = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "    fingerprints_map: np.ndarray = map_generator.calculate_many_sparse(\n",
    "        molecules,\n",
    "        number_of_threads=32,\n",
    "        verbose=True,\n",
    "        count=count,\n",
    "    )\n",
    "    return list(fingerprints_map)\n",
    "\n",
    "\n",
    "def compute_sparse_map_fingerprints_from_smiles_serial(\n",
    "        smiles,\n",
    "        map_generator\n",
    "        ):\n",
    "\n",
    "    molecules: List[Mol] = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "    fingerprints = []\n",
    "    for mol in tqdm(molecules):\n",
    "        fp_bits = map_generator._calculate(mol)\n",
    "        fingerprints.append(np.sort(map_generator.encoder.hash(fp_bits)))\n",
    "    return fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df62bb0-43a2-4ff7-9e8d-935017abf401",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    (\"morgan2_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096), True),\n",
    "    (\"morgan3_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096), True),\n",
    "    (\"morgan6_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=6, fpSize=4096), True),\n",
    "    (\"morgan9_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=4096), True),\n",
    "    (\"morgan12_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=12, fpSize=4096), True),\n",
    "    (\"morgan2_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096), False),\n",
    "    (\"morgan3_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096), False),\n",
    "    (\"morgan6_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=6, fpSize=4096), False),\n",
    "    (\"morgan9_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=4096), False),\n",
    "    (\"morgan12_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=12, fpSize=4096), False),\n",
    "    (\"rdkit_sparse\", rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=4096), False),\n",
    "    (\"map2_sparse\", MAP4(dimensions=4096, radius=1, include_duplicated_shingles=False), False),\n",
    "    (\"map4_sparse\", MAP4(dimensions=4096, radius=2, include_duplicated_shingles=False), False),\n",
    "    (\"mbp2_sparse\", MBP(dimensions=4096, radius=1), False),\n",
    "    (\"mbp2_binned_sparse\", MBP(dimensions=4096, radius=1, dist_binning=np.array([0, 1, 2, 4, 8, 16, 32, 64])), False),\n",
    "    (\"mbp2_count_sparse\", MBP(dimensions=4096, radius=1), True),\n",
    "    (\"mbp2_binned_count_sparse\", MBP(dimensions=4096, radius=1, dist_binning=np.array([0, 1, 2, 4, 8, 16, 32, 64])), True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16953b8c-276c-4ef6-a495-b2af902c4e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Experiment: morgan2_count_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████▊                    | 284107/730464 [00:40<01:03, 6974.99it/s][09:21:01] WARNING: not removing hydrogen atom without neighbors\n",
      " 76%|█████████████████████████        | 555396/730464 [01:19<00:25, 6994.82it/s][09:21:39] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|███████████████████████████████▌ | 699208/730464 [01:39<00:04, 6958.46it/s][09:22:00] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|█████████████████████████████████| 730464/730464 [01:44<00:00, 6996.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 74579 compounds have duplicated fingerprints.\n",
      "The largest cluster has 381 compounds with identical fingerprint.\n",
      "----- Experiment: morgan3_count_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████▊                    | 284069/730464 [00:48<01:17, 5748.44it/s][09:22:54] WARNING: not removing hydrogen atom without neighbors\n",
      " 76%|█████████████████████████        | 555182/730464 [01:34<00:30, 5800.76it/s][09:23:41] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|███████████████████████████████▌ | 699229/730464 [01:59<00:05, 5955.11it/s][09:24:05] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|█████████████████████████████████| 730464/730464 [02:04<00:00, 5861.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 65175 compounds have duplicated fingerprints.\n",
      "The largest cluster has 381 compounds with identical fingerprint.\n",
      "----- Experiment: morgan6_count_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████▊                    | 283959/730464 [01:10<01:54, 3913.81it/s][09:25:22] WARNING: not removing hydrogen atom without neighbors\n",
      " 76%|█████████████████████████        | 555560/730464 [02:18<00:44, 3927.04it/s][09:26:30] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|███████████████████████████████▌ | 699274/730464 [02:53<00:07, 4100.52it/s][09:27:05] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|█████████████████████████████████| 730464/730464 [03:01<00:00, 4025.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 43916 compounds have duplicated fingerprints.\n",
      "The largest cluster has 81 compounds with identical fingerprint.\n",
      "----- Experiment: morgan9_count_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████▊                    | 284041/730464 [01:28<02:24, 3092.52it/s][09:28:44] WARNING: not removing hydrogen atom without neighbors\n",
      " 76%|█████████████████████████        | 555465/730464 [02:53<00:55, 3168.63it/s][09:30:09] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|███████████████████████████████▌ | 699129/730464 [03:37<00:09, 3319.57it/s][09:30:53] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|█████████████████████████████████| 730464/730464 [03:47<00:00, 3211.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 21250 compounds have duplicated fingerprints.\n",
      "The largest cluster has 7 compounds with identical fingerprint.\n",
      "----- Experiment: morgan12_count_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████▊                    | 284046/730464 [01:42<02:43, 2738.36it/s][09:32:47] WARNING: not removing hydrogen atom without neighbors\n",
      " 76%|█████████████████████████        | 555663/730464 [03:20<01:02, 2807.35it/s][09:34:25] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|███████████████████████████████▌ | 699293/730464 [04:11<00:10, 2988.71it/s][09:35:16] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|█████████████████████████████████| 730464/730464 [04:23<00:00, 2775.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 10007 compounds have duplicated fingerprints.\n",
      "The largest cluster has 3 compounds with identical fingerprint.\n",
      "----- Experiment: morgan2_binary_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████▊                    | 283883/730464 [00:39<01:01, 7231.43it/s][09:36:09] WARNING: not removing hydrogen atom without neighbors\n",
      " 76%|█████████████████████████        | 555035/730464 [01:16<00:23, 7360.47it/s][09:36:46] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|███████████████████████████████▌ | 699150/730464 [01:36<00:04, 7334.59it/s][09:37:06] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|█████████████████████████████████| 730464/730464 [01:40<00:00, 7250.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 101029 compounds have duplicated fingerprints.\n",
      "The largest cluster has 11332 compounds with identical fingerprint.\n",
      "----- Experiment: morgan3_binary_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████▊                    | 283738/730464 [00:47<01:15, 5915.21it/s][09:37:59] WARNING: not removing hydrogen atom without neighbors\n",
      " 76%|█████████████████████████        | 555141/730464 [01:32<00:29, 5917.73it/s][09:38:44] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|███████████████████████████████▌ | 699169/730464 [01:56<00:05, 6134.88it/s][09:39:08] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|█████████████████████████████████| 730464/730464 [02:01<00:00, 5995.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 87066 compounds have duplicated fingerprints.\n",
      "The largest cluster has 11332 compounds with identical fingerprint.\n",
      "----- Experiment: morgan6_binary_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████▊                    | 284026/730464 [01:09<01:52, 3970.59it/s][09:40:23] WARNING: not removing hydrogen atom without neighbors\n",
      " 76%|█████████████████████████        | 555332/730464 [02:15<00:43, 4060.48it/s][09:41:30] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|███████████████████████████████▌ | 699292/730464 [02:50<00:07, 4279.85it/s][09:42:05] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|█████████████████████████████████| 730464/730464 [02:57<00:00, 4104.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 62802 compounds have duplicated fingerprints.\n",
      "The largest cluster has 1762 compounds with identical fingerprint.\n",
      "----- Experiment: morgan9_binary_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████▊                    | 283985/730464 [01:28<02:25, 3074.72it/s][09:43:42] WARNING: not removing hydrogen atom without neighbors\n",
      " 76%|█████████████████████████        | 555488/730464 [02:53<00:56, 3122.67it/s][09:45:07] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|███████████████████████████████▌ | 698977/730464 [03:37<00:09, 3430.29it/s][09:45:51] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|█████████████████████████████████| 730464/730464 [03:46<00:00, 3220.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 30794 compounds have duplicated fingerprints.\n",
      "The largest cluster has 58 compounds with identical fingerprint.\n",
      "----- Experiment: morgan12_binary_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████▊                    | 284227/730464 [01:42<02:42, 2745.15it/s][09:47:44] WARNING: not removing hydrogen atom without neighbors\n",
      " 76%|█████████████████████████        | 555398/730464 [03:18<01:03, 2738.34it/s][09:49:20] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|███████████████████████████████▌ | 699012/730464 [04:09<00:10, 2991.03it/s][09:50:11] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|█████████████████████████████████| 730464/730464 [04:20<00:00, 2801.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 10863 compounds have duplicated fingerprints.\n",
      "The largest cluster has 24 compounds with identical fingerprint.\n",
      "----- Experiment: rdkit_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████▏                    | 284241/730464 [07:56<13:09, 565.48it/s][09:58:20] WARNING: not removing hydrogen atom without neighbors\n",
      " 76%|█████████████████████████▊        | 555654/730464 [16:03<04:40, 624.22it/s][10:06:27] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|████████████████████████████████▌ | 699268/730464 [20:34<00:46, 675.08it/s][10:10:58] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|██████████████████████████████████| 730464/730464 [21:24<00:00, 568.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 130788 compounds have duplicated fingerprints.\n",
      "The largest cluster has 14153 compounds with identical fingerprint.\n",
      "----- Experiment: map2_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:12:15] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:12:36] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:12:47] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e69d1bade244db8dd436569f5527ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/730464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 1625 compounds have duplicated fingerprints.\n",
      "The largest cluster has 176 compounds with identical fingerprint.\n",
      "----- Experiment: map4_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:22:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:22:48] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:22:58] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ed2577d73744209020725ca90715ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/730464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 218 compounds have duplicated fingerprints.\n",
      "The largest cluster has 176 compounds with identical fingerprint.\n",
      "----- Experiment: mbp2_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:42:21] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:42:41] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:42:52] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40eba176ab04fc7abaa13a53bb76d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating sparse fingerprints:   0%|          | 0/730464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 730464 fingerprints.\n",
      "Total of 308 compounds have duplicated fingerprints.\n",
      "The largest cluster has 176 compounds with identical fingerprint.\n",
      "----- Experiment: mbp2_binned_sparse -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:25:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:26:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:26:56] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7d472975894765ae2a1dce217e6f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating sparse fingerprints:   0%|          | 0/730464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to store collected duplicates and bit occupations\n",
    "path_results = os.path.join(Path(ROOT), \"experiments\", \"fingerprint_duplicates\")\n",
    "\n",
    "# Run experiments!\n",
    "for experiment in experiments:\n",
    "    (name, fpgen, count) = experiment\n",
    "    if os.path.exists(os.path.join(path_results, f\"{name}_duplicates.pickle\")):\n",
    "        print(f\"----- Found existing results for experiment: {name} -----\")\n",
    "        print(f\"----- (experiment will be skipped) -----\")\n",
    "        continue\n",
    "\n",
    "    print(f\"----- Experiment: {name} -----\")\n",
    "\n",
    "    # Compute fingerprints\n",
    "    if (\"map\" in name):\n",
    "        fingerprints = compute_sparse_map_fingerprints_from_smiles_serial(compounds.smiles, fpgen)\n",
    "    elif (\"mbp\" in name):\n",
    "        if count:\n",
    "            fingerprints = compute_sparse_map_fingerprints_from_smiles(compounds.smiles, fpgen, count=True)\n",
    "            fingerprints = [(x[0], x[1]) for x in fingerprints]\n",
    "        else:\n",
    "            fingerprints = compute_sparse_map_fingerprints_from_smiles(compounds.smiles, fpgen)\n",
    "    else:\n",
    "        fingerprints = compute_fingerprints_from_smiles(\n",
    "            compounds.smiles, fpgen, sparse=True,\n",
    "            count=count, progress_bar=True\n",
    "        )\n",
    "\n",
    "    print(f\"Collected {len(fingerprints)} fingerprints.\")\n",
    "\n",
    "    # Bit statistics\n",
    "    if isinstance(fingerprints[0], tuple):\n",
    "        number_of_bits = np.array([len(x[0]) for x in fingerprints])\n",
    "    else:\n",
    "        number_of_bits = np.array([len(x) for x in fingerprints])\n",
    "    np.save(os.path.join(path_results, f\"{name}_number_of_bits.npy\"), number_of_bits)\n",
    "\n",
    "    # Search fingerprint duplicates\n",
    "    duplicates = find_duplicates_with_hashing(fingerprints)\n",
    "    duplicate_statistics = np.array([len(x) for x in duplicates])\n",
    "    with open(os.path.join(path_results, f\"{name}_duplicates.pickle\"), \"wb\") as handle:\n",
    "        pickle.dump(duplicates, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"Total of {sum(duplicate_statistics)} compounds have duplicated fingerprints.\")\n",
    "    if len(duplicate_statistics) > 0:\n",
    "        print(f\"The largest cluster has {max(duplicate_statistics)} compounds with identical fingerprint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4762ef05-c368-43c6-8304-2641da81ee6b",
   "metadata": {},
   "source": [
    "## Compare experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e15ec-0919-4004-9da0-4362669773d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    (\"morgan2_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096), True),\n",
    "    (\"morgan3_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096), True),\n",
    "    #(\"morgan6_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=6, fpSize=4096), True),\n",
    "    (\"morgan9_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=4096), True),\n",
    "    (\"morgan12_count_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=12, fpSize=4096), True),\n",
    "    (\"morgan2_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096), False),\n",
    "    (\"morgan3_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096), False),\n",
    "    (\"morgan9_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=9, fpSize=4096), False),\n",
    "    (\"morgan12_binary_sparse\", rdFingerprintGenerator.GetMorganGenerator(radius=12, fpSize=4096), False),\n",
    "    (\"rdkit_sparse\", rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=4096), False),\n",
    "    (\"map2_sparse\", MAP4(dimensions=4096, radius=1, include_duplicated_shingles=False), False),\n",
    "    (\"map4_sparse\", MAP4(dimensions=4096, radius=2, include_duplicated_shingles=False), False),\n",
    "    #(\"mbp2_sparse\", MBP(dimensions=4096, radius=1), False),\n",
    "    #(\"mbp2_binned_sparse\", MBP(dimensions=4096, radius=1, dist_binning=np.array([0, 1, 2, 4, 8, 16, 32, 64])), False),\n",
    "    #(\"mbp2_count_sparse\", MBP(dimensions=4096, radius=1), True),\n",
    "    #(\"mbp2_binned_count_sparse\", MBP(dimensions=4096, radius=1, dist_binning=np.array([0, 1, 2, 4, 8, 16, 32, 64])), True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2fa7e7-0424-4f03-b9e6-a2289da19cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group_mass_diff(group_indices, masses):\n",
    "    \"\"\"\n",
    "    Given a list/array of indices corresponding to compounds in a duplicate group,\n",
    "    compute the mass range (max - min) for that group.\n",
    "    \"\"\"\n",
    "    group_masses = masses[group_indices]\n",
    "    return group_masses.max() - group_masses.min()\n",
    "\n",
    "\n",
    "results_folder = os.path.join(Path(ROOT), \"experiments\", \"fingerprint_duplicates\")\n",
    "experiment_names = [x[0] for x in experiments]\n",
    "experiment_names.extend([x[0].replace(\"_sparse\", \"\") for x in experiments])\n",
    "\n",
    "\n",
    "results = []\n",
    "for exp_name in tqdm(experiment_names):\n",
    "    dup_file = os.path.join(results_folder, f\"{exp_name}_duplicates.pickle\")\n",
    "    bins_file = os.path.join(results_folder, f\"{exp_name}_bins_occupied.npy\")\n",
    "    bit_number_file = os.path.join(results_folder, f\"{exp_name}_number_of_bits.npy\")\n",
    "    \n",
    "    # If either file is missing, skip this experiment.\n",
    "    if not os.path.exists(dup_file) and (os.path.exists(bins_file) or os.path.exists(bit_number_file)):\n",
    "        print(f\"Results for experiment {exp_name} not found, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load duplicate groups.\n",
    "    with open(dup_file, \"rb\") as f:\n",
    "        duplicates = pickle.load(f)\n",
    "\n",
    "    # Total duplicates: count all compounds that appear in any duplicate group.\n",
    "    total_duplicates = sum(len(group) for group in duplicates)\n",
    "    \n",
    "    # Count the duplicates in groups where the max-mass difference is at least 200.\n",
    "    duplicates_mass_diff = 0\n",
    "    for group in duplicates:\n",
    "        # Convert group to a NumPy array (if not already) to index into masses.\n",
    "        group_indices = np.array(group)\n",
    "        if len(group_indices) == 0:\n",
    "            continue  # Skip if group is empty for any reason.\n",
    "        mass_diff = compute_group_mass_diff(group_indices, masses)\n",
    "        if mass_diff >= 200:\n",
    "            duplicates_mass_diff += len(group_indices)\n",
    "\n",
    "    if \"_sparse\" in exp_name:\n",
    "        # Load the bit data.\n",
    "        bit_numbers = np.load(bit_number_file)\n",
    "        mean_bins = bit_numbers.mean()\n",
    "    else:\n",
    "        # Load the bins occupancy data.\n",
    "        bins_occupied = np.load(bins_file)\n",
    "        mean_bins = bins_occupied.mean() / 100 * len(bins_occupied)\n",
    "\n",
    "    # Append the experiment summary to our results list.\n",
    "    results.append({\n",
    "        \"experiment\": exp_name,\n",
    "        \"total_duplicates\": total_duplicates,\n",
    "        \"duplicates_mass_diff_ge_200\": duplicates_mass_diff,\n",
    "        \"mean_bins_occupied\": mean_bins,\n",
    "    })\n",
    "\n",
    "# Create a Pandas DataFrame for a neat summary.\n",
    "df_results = pd.DataFrame(results).sort_values(\"experiment\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b5b45-63f1-4f09-858f-f738f4060bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "df_results.to_csv(\"results_table_fingerprint_statistics_250505.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e0f24c-60df-4a61-8546-1c9099d9aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_experiments = [\n",
    "    (\"rdkit\", \"RDKit fingerprint (4096 bits)\"),\n",
    "    (\"rdkit_1024\", \"RDKit fingerprint (1024 bits)\"),\n",
    "    (\"morgan2_binary\", \"Morgan-2 fingerprint (4096 bits)\"),\n",
    "    (\"morgan2_count\", \"Morgan-2 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan2_binary_1024\", \"Morgan-2 fingerprint (1024 bits)\"),\n",
    "    (\"morgan3_binary\", \"Morgan-3 fingerprint (4096 bits)\"),\n",
    "    (\"morgan3_count\", \"Morgan-3 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan3_binary_1024\", \"Morgan-3 fingerprint (1024 bits)\"),\n",
    "    #(\"morgan6_count\", \"Morgan-6 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan6_binary\", \"Morgan-6 fingerprint (4096 bits)\"),\n",
    "    (\"morgan6_binary_1024\", \"Morgan-6 fingerprint (1024 bits)\"),\n",
    "    (\"morgan9_binary\", \"Morgan-9 fingerprint (4096 bits)\"),\n",
    "    (\"morgan9_binary_1024\", \"Morgan-9 fingerprint (1024 bits)\"),\n",
    "    (\"map4\", \"MAP4 fingerprint (4096 bits)\"),\n",
    "    (\"map4_1024\", \"MAP4 fingerprint (1024 bits)\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d63dc9b-8d09-47f4-87f3-3d0446a9a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    \"#00A878\", \"#00A878\",\n",
    "    \"#fad02c\", \"#fad02c\",\n",
    "    \"#f98517\", \"#f98517\",\n",
    "    #\"#c85b00\", \"#c85b00\",\n",
    "    \"#ac0000\", \"#ac0000\",\n",
    "    \"#680000\", \"#680000\",\n",
    "    \"#3333D1\", \"#3333D1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f23ec3-9be1-4831-92e1-1191c437c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5), dpi=300)\n",
    "\n",
    "fig_i = -1\n",
    "for i, (file, name) in enumerate(files_experiments):\n",
    "    if \"count\" in name:\n",
    "        if file[:7]+\"_binary\" in [x[0] for x in files_experiments]:\n",
    "            continue\n",
    "    fig_i += 1\n",
    "    bins_occupied = np.load(os.path.join(path_results, f\"{file}_bins_occupied.npy\"))\n",
    "    order = np.argsort(bins_occupied)[::-1]\n",
    "    bins_scaled = np.linspace(0, 100, len(bins_occupied))\n",
    "\n",
    "\n",
    "    if \"1024\" in name:\n",
    "        ax.plot(bins_scaled, bins_occupied[order], \":\", linewidth=1.5, color=colors[fig_i], alpha=0.9, label=name.replace(\" count\", \"\"))\n",
    "    else:\n",
    "        ax.plot(bins_scaled, bins_occupied[order], linewidth=1.5, color=colors[fig_i], label=name.replace(\" count\", \"\"))\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"bit occupation [%]\")\n",
    "ax.set_xlabel(\"vector length [%]\")\n",
    "ax.set_xlim([0, 100])\n",
    "ax.set_ylim([0, 100])\n",
    "\n",
    "# Grid\n",
    "ax.grid(which='major', color='#DDDDDD', linewidth=1)\n",
    "ax.grid(which='minor', color='#EEEEEE', linestyle=':', linewidth=0.75)\n",
    "\n",
    "plt.legend(fontsize=7)\n",
    "plt.savefig(\"Bit_occupation_distributions_scaled_730k.pdf\")\n",
    "plt.savefig(\"Bit_occupation_distributions_scaled_730k.png\", dpi=450)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc2eff-6ee4-4ceb-8f9f-31510ef5f8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e002e-af82-472f-a487-93cf6633b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "#plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cbe812-5d2c-49df-800f-17c6d6aed187",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_experiments = [\n",
    "    (\"rdkit\", \"RDKit fingerprint (4096 bits)\"),\n",
    "    (\"rdkit_1024\", \"RDKit fingerprint (1024 bits)\"),\n",
    "    (\"morgan2_binary\", \"Morgan-2 fingerprint (4096 bits)\"),\n",
    "    (\"morgan2_count\", \"Morgan-2 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan2_binary_1024\", \"Morgan-2 fingerprint (1024 bits)\"),\n",
    "    (\"morgan3_binary\", \"Morgan-3 fingerprint (4096 bits)\"),\n",
    "    (\"morgan3_count\", \"Morgan-3 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan3_binary_1024\", \"Morgan-3 fingerprint (1024 bits)\"),\n",
    "    (\"morgan4_count\", \"Morgan-4 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan5_count\", \"Morgan-5 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan6_count\", \"Morgan-6 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan6_binary_1024\", \"Morgan-6 fingerprint (1024 bits)\"),\n",
    "    (\"map4_4096\", \"MAP4 fingerprint (r=2, 4096 bits)\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051f7607-5248-4cb1-ad03-16e8eaf7ccfb",
   "metadata": {},
   "source": [
    "## TAKE CARE: this will take the max difference per duplicates group\n",
    "This is rather pessimistic, but might give an idea of the \"risk\" to find *very* different compounds for the same fingerprints.\n",
    "\n",
    "After all 5 identical fingerprints with masses [200, 210, 350, 380, 500] would not all correspond to a max mass difference of 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90451ece-930b-4b7a-ad1f-98e33589c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_compound_max_differences(masses):\n",
    "    all_max_diffs = []\n",
    "    min_mass = masses.min()\n",
    "    max_mass = masses.max()\n",
    "    for mass in masses:\n",
    "        max_diff = max(mass - min_mass, max_mass - mass)\n",
    "        all_max_diffs.append(max_diff)\n",
    "\n",
    "    return np.array(all_max_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5396df-3dab-4565-9845-9ee1929c9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#00A878\", \"#6CCD8C\",\n",
    "          \"#E6D98C\", \"#F1C178\",\n",
    "          \"#F16666\", \"#DD2222\",\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc0fec0-1587-4e4d-b2a2-14f706f2c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_experiments = [\n",
    "    (\"rdkit\", \"RDKit fingerprint (4096 bits)\"),\n",
    "    (\"rdkit_1024\", \"RDKit fingerprint (1024 bits)\"),\n",
    "    (\"morgan2_binary\", \"Morgan-2 fingerprint (4096 bits)\"),\n",
    "    (\"morgan2_count\", \"Morgan-2 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan2_binary_1024\", \"Morgan-2 fingerprint (1024 bits)\"),\n",
    "    (\"morgan3_binary\", \"Morgan-3 fingerprint (4096 bits)\"),\n",
    "    (\"morgan3_count\", \"Morgan-3 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan3_binary_1024\", \"Morgan-3 fingerprint (1024 bits)\"),\n",
    "    (\"morgan6_count\", \"Morgan-6 count fingerprint (4096 bits)\"),\n",
    "    (\"morgan6_binary\", \"Morgan-6 fingerprint (4096 bits)\"),\n",
    "    (\"morgan6_binary_1024\", \"Morgan-6 fingerprint (1024 bits)\"),\n",
    "    (\"morgan9_count\", \"Morgan-9 count fingerprint (4096 bits)\"),\n",
    "    #(\"map2\", \"MAP2 fingerprint (4096 bits)\"),\n",
    "    (\"map4\", \"MAP4 fingerprint (4096 bits)\"),\n",
    "    (\"map4_1024\", \"MAP4 fingerprint (1024 bits)\"),\n",
    "    #(\"biosynphoni\", \"Biosynfoni fingerprint\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa798e-ce31-4487-b2b4-dca56592fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bins\n",
    "bins = [(0, 1), (1, 50), (50, 100), (100, 200), (200, 400), (400, np.inf)]\n",
    "bin_labels = [f\"{low}-{high} Da\" if high != np.inf else f\"{low}-inf Da\" for low, high in bins]\n",
    "\n",
    "\n",
    "# Initialize results storage\n",
    "experiment_sums = {name: np.zeros(len(bins)) for _, name in files_experiments}\n",
    "\n",
    "# Process each experiment\n",
    "for file, name in files_experiments:\n",
    "    # Load duplicates data\n",
    "    with open(os.path.join(path_results, f\"{file}_duplicates.pickle\"), \"rb\") as f:\n",
    "        duplicates = pickle.load(f)\n",
    "\n",
    "    # Calculate statistics\n",
    "    duplicate_statistics = np.array([len(x) for x in duplicates])\n",
    "    duplicate_masses = [masses[i] for i in duplicates]\n",
    "    max_mass_differences = np.concatenate([compute_compound_max_differences(x) for x in duplicate_masses])\n",
    "\n",
    "    # Compute sums for each bin\n",
    "    for i, (low, high) in enumerate(bins):\n",
    "        idx = np.where((max_mass_differences >= low) & (max_mass_differences < high))[0]\n",
    "        experiment_sums[name][i] = idx.shape[0]\n",
    "\n",
    "# Sort experiments by total sum\n",
    "sorted_experiments = sorted(\n",
    "    experiment_sums.items(), \n",
    "    key=lambda item: item[1].sum(), \n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Prepare for stacked bar chart\n",
    "width = 0.5\n",
    "y_positions = np.arange(len(sorted_experiments))\n",
    "left_stack = np.zeros(len(sorted_experiments))\n",
    "\n",
    "# Iterate over bins and stack their sums\n",
    "for i, label in enumerate(bin_labels):\n",
    "    values = [experiment[1][i] for experiment in sorted_experiments]\n",
    "    ax.barh(y_positions, values, width, label=label, left=left_stack, color=colors[i])\n",
    "    left_stack += values\n",
    "\n",
    "# Add numbers\n",
    "for i, y in enumerate(y_positions):\n",
    "    value = sorted_experiments[i][1].sum()\n",
    "    plt.text(value, i-0.1, f\"{value:.0f}\", fontsize=9)\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(which='major', color='#DDDDDD', linewidth=1)\n",
    "\n",
    "# Configure plot appearance\n",
    "ax.set_yticks(y_positions)\n",
    "ax.set_yticklabels([experiment[0] for experiment in sorted_experiments])\n",
    "ax.set_xlabel(\"Compounds with Fingerprint Duplicates\")\n",
    "ax.set_title(\"Duplicate Statistics by Experiment (Sorted by total duplicates)\")\n",
    "ax.legend(title=\"Maximum mass difference\\n(for identical fingerprints)\", loc=\"upper right\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Duplicate_statistics_max_mass_difference_730k.pdf\")\n",
    "plt.savefig(\"Duplicate_statistics_max_mass_difference_730k.png\", dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a27dab-c2da-424d-a9d2-76ac9bb5ff6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
